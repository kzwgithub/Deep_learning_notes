<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  

  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hexo">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-assignment2_2_note" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/12/04/assignment2_2_note/" class="article-date">
  <time datetime="2018-12-04T02:30:48.700Z" itemprop="datePublished">2018-12-04</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="任务2-1-逻辑回归-用神经网络思维"><a href="#任务2-1-逻辑回归-用神经网络思维" class="headerlink" title="任务2_1 : 逻辑回归(用神经网络思维)"></a>任务2_1 : 逻辑回归(用神经网络思维)</h1><h2 id="1-数据的预处理-归一化"><a href="#1-数据的预处理-归一化" class="headerlink" title="1.数据的预处理,归一化"></a>1.数据的预处理,归一化</h2><h3 id="数据预处理的一般步骤"><a href="#数据预处理的一般步骤" class="headerlink" title="数据预处理的一般步骤:"></a>数据预处理的一般步骤:</h3><ol>
<li>确定数据集的demensions和shape(m_train, m_test, w_px, h_px …)</li>
<li>reshape数据集成一个向量:shape=(num_train, w_px, h_px, 3) –&gt; shape=(num_train, w_px <em> h_px </em> 3)<br><img src="https://i.imgur.com/werK0ce.jpg" alt=""></li>
</ol>
<h3 id="数据归一化"><a href="#数据归一化" class="headerlink" title="数据归一化:"></a>数据归一化:</h3><ol>
<li>常见的数据归一化方式: 减去数组平均值 –&gt; 除以数组标准差</li>
<li>图片数据归一化 : 每个样本除以255（像素通道的最大值）<h3 id="断言的使用-对定向确定bug很有效"><a href="#断言的使用-对定向确定bug很有效" class="headerlink" title="断言的使用: 对定向确定bug很有效"></a>断言的使用: 对定向确定bug很有效</h3> assert(w.shape == (dim, 1))<br> assert(isinstance(b, float) or isinstance(b, int))</li>
</ol>
<h2 id="2-学习算法的一般结构"><a href="#2-学习算法的一般结构" class="headerlink" title="2.学习算法的一般结构"></a>2.学习算法的一般结构</h2><h3 id="结构"><a href="#结构" class="headerlink" title="结构:"></a>结构:</h3><p><img src="https://i.imgur.com/8v7MUvc.jpg" alt=""></p>
<h3 id="学习算法的实现过程"><a href="#学习算法的实现过程" class="headerlink" title="学习算法的实现过程:"></a>学习算法的实现过程:</h3><ol>
<li>初始化模型参数</li>
<li>通过最小化cost来学习模型的参数(training set)</li>
<li>使用学习到的参数做预测(test set)</li>
<li>分析结果,得出结论<h3 id="前向传播-二分类逻辑回归"><a href="#前向传播-二分类逻辑回归" class="headerlink" title="前向传播(二分类逻辑回归):"></a>前向传播(二分类逻辑回归):</h3><img src="https://i.imgur.com/yv47AKa.jpg" alt=""><h3 id="后向传播-二分类逻辑回归"><a href="#后向传播-二分类逻辑回归" class="headerlink" title="后向传播(二分类逻辑回归):"></a>后向传播(二分类逻辑回归):</h3><img src="https://i.imgur.com/NVLNaiD.jpg" alt=""></li>
</ol>
<h2 id="3-建立神经网络的一般步骤"><a href="#3-建立神经网络的一般步骤" class="headerlink" title="3.建立神经网络的一般步骤"></a>3.建立神经网络的一般步骤</h2><h3 id="步骤"><a href="#步骤" class="headerlink" title="步骤:"></a>步骤:</h3><ol>
<li>定义模型结构</li>
<li>初始化模型参数</li>
<li>迭代学习模型参数: 前向传播 -&gt; 计算cost -&gt; 后向传播 -&gt; 计算grad -&gt; 更新参数(梯度下降)</li>
<li>在test set上做预测<h3 id="one-more-thing"><a href="#one-more-thing" class="headerlink" title="one more thing:"></a>one more thing:</h3></li>
</ol>
<ul>
<li>通常都会把step1-3整合到一个函数中(nn_model),然后就可以:建立model -&gt; 学习参数 -&gt; 在新数据上做预测</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/12/04/assignment2_2_note/" data-id="cjp962nbd0001f0g6jfmo2sfy" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-assignment2_1_note" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/12/04/assignment2_1_note/" class="article-date">
  <time datetime="2018-12-04T02:30:48.695Z" itemprop="datePublished">2018-12-04</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="任务2-1-Python-numpy-基础练习"><a href="#任务2-1-Python-numpy-基础练习" class="headerlink" title="任务2_1 :Python numpy 基础练习"></a>任务2_1 :Python numpy 基础练习</h1><h2 id="1-normalization"><a href="#1-normalization" class="headerlink" title="1.normalization"></a>1.normalization</h2><p>###示例:按行归一化<br>    x = [[0,3,4],[2,6,4]]<br>    x_norm = np.linalg.norm(x,ord=2,axis=1,keepdims=True) #=[5,根号(56)]<br>    x_normalized = x/x_norm = [[0,3/5,4/5],[2/根号(56),6/根号(56),4/根号(56)]]</p>
<p>###注意 : </p>
<ul>
<li>axis=1 : 按行归一化</li>
<li>keepdims : 保持矩阵原有的形状 -&gt; 便于brodacast</li>
<li>ord : 范数,默认是求2范数</li>
<li><p>向量的范数 : </p>
<p><img src="https://i.imgur.com/LEd3HZB.png" alt=""></p>
</li>
</ul>
<h2 id="2-the-gradient-of-sigmoid"><a href="#2-the-gradient-of-sigmoid" class="headerlink" title="2.the gradient of sigmoid"></a>2.the gradient of sigmoid</h2><p>###示例:<br>    sigmoid_derivative(x) = σ′(x) = σ(x)(1−σ(x))</p>
<h2 id="3-L1损失和L2损失"><a href="#3-L1损失和L2损失" class="headerlink" title="3.L1损失和L2损失"></a>3.L1损失和L2损失</h2><ul>
<li>L1损失 : </li>
</ul>
<p><img src="https://i.imgur.com/VHJwx0v.jpg" alt=""></p>
<ul>
<li>L2损失 : </li>
</ul>
<p><img src="https://i.imgur.com/Dz1q37K.jpg" alt=""></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/12/04/assignment2_1_note/" data-id="cjp962nb50000f0g6xekf63wz" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-课程目录" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/12/04/课程目录/" class="article-date">
  <time datetime="2018-12-04T02:17:10.053Z" itemprop="datePublished">2018-12-04</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <ul>
<li>1_神经网络与深度学习<ul>
<li>第一周-深度学习概论-1.1-欢迎</li>
<li>第一周-深度学习概论-1.2-什么是神剧网络</li>
<li>第一周-深度学习概论-1.3-用神经网络进行监督学习</li>
<li>第一周-深度学习概论-1.4-为什么深度学习会兴起</li>
<li>第一周-深度学习概论-1.5-关于这门课程</li>
<li>第一周-深度学习概论-1.6-课程资源</li>
<li></li>
<li>第二周-神经网络基础-2.1-二分类</li>
<li>第二周-神经网络基础-2.2-logistic回归</li>
<li>第二周-神经网络基础-2.3-logistic回归损失函数</li>
<li>第二周-神经网络基础-2.4-梯度下降法</li>
<li>第二周-神经网络基础-2.5-导数</li>
<li>第二周-神经网络基础-2.6-更多导数的例子</li>
<li>第二周-神经网络基础-2.7-计算图</li>
<li>第二周-神经网络基础-2.8-计算图的导数计算</li>
<li>第二周-神经网络基础-2.9-logistic回归的梯度下降法</li>
<li>第二周-神经网络基础-2.10-m个样本的梯度下降</li>
<li>第二周-神经网络基础-2.11-向量化</li>
<li>第二周-神经网络基础-2.12-向量化的更多例子</li>
<li>第二周-神经网络基础-2.13-向量化logistic回归</li>
<li>第二周-神经网络基础-2.14-向量化logistic回归的梯度输出</li>
<li>第二周-神经网络基础-2.15-python中的广播</li>
<li>第二周-神经网络基础-2.16-关于python/numpy向量的说明</li>
<li>第二周-神经网络基础-2.17-jupyter/Ipython笔记本的快速指南</li>
<li>第二周-神经网络基础-2.18-logistic损失函数的解释</li>
<li></li>
<li>第三周-浅层神经网络-3.1-神经网络概览</li>
<li>第三周-浅层神经网络-3.2-神经网络表示</li>
<li>第三周-浅层神经网络-3.3-计算神经网络的输出</li>
<li>第三周-浅层神经网络-3.4-多个例子中的向量化</li>
<li>第三周-浅层神经网络-3.5-向量化实现的解释</li>
<li>第三周-浅层神经网络-3.6-激活函数</li>
<li>第三周-浅层神经网络-3.7-为什么需要非线性激活函数</li>
<li>第三周-浅层神经网络-3.8-激活函数的导数</li>
<li>第三周-浅层神经网络-3.9-神经网络的梯度下降</li>
<li>第三周-浅层神经网络-3.10-（选修）直观理解反向传播</li>
<li>第三周-浅层神经网络-3.11-随机初始化</li>
<li></li>
<li>第四周-深层神经网络-4.1-深层神经网络</li>
<li>第四周-深层神经网络-4.2-深层网络的前向传播</li>
<li>第四周-深层神经网络-4.3-核对矩阵的维数</li>
<li>第四周-深层神经网络-4.4-为什么使用深层表示</li>
<li>第四周-深层神经网络-4.5-搭建深层神经网络块</li>
<li>第四周-深层神经网络-4.6-前向和反向传播</li>
<li>第四周-深层神经网络-4.7-参数VS超参数</li>
<li>第四周-深层神经网络-4.8-这和大脑有什么关系</li>
</ul>
</li>
</ul>
<ul>
<li><p>2_改善深层神经网络：超参数调试、正则化以及优化</p>
<ul>
<li>第一周-深层学习的实用-1.1-训练/开发/测试集</li>
<li>第一周-深层学习的实用-1.2-偏差/方差</li>
<li>第一周-深层学习的实用-1.3-机器学习基础</li>
<li>第一周-深层学习的实用-1.4-正则化</li>
<li>第一周-深层学习的实用-1.5-为什么正则化可以减少过拟合</li>
<li>第一周-深层学习的实用-1.6-DropOut正则化</li>
<li>第一周-深层学习的实用-1.7-理解DropOut</li>
<li>第一周-深层学习的实用-1.8-其他正则化方法</li>
<li>第一周-深层学习的实用-1.9-正则化输入</li>
<li>第一周-深层学习的实用-1.10-梯度小时与梯度爆炸</li>
<li>第一周-深层学习的实用-1.11-神经网络的权重初始化</li>
<li>第一周-深层学习的实用-1.12-梯度的数值逼近</li>
<li>第一周-深层学习的实用-1.13-梯度校验</li>
<li>第一周-深层学习的实用-1.14-关于梯度校验实现的标记</li>
<li></li>
<li>第二周-优化算法-2.1-Minibath梯度下降法</li>
<li>第二周-优化算法-2.2-理解Minibath梯度下降法</li>
<li>第二周-优化算法-2.3-指数加权平均</li>
<li>第二周-优化算法-2.4-理解指数加权平均</li>
<li>第二周-优化算法-2.5-指数指数加权平均的偏差修正</li>
<li>第二周-优化算法-2.6-动量梯度下降法</li>
<li>第二周-优化算法-2.7-RMSprop</li>
<li>第二周-优化算法-2.8-Adam 优化算法</li>
<li>第二周-优化算法-2.9-学习率衰减</li>
<li>第二周-优化算法-2.10-局部最优问题</li>
<li></li>
<li>第三周-超参数调试&amp;正则化&amp;框架-3.1-调试处理</li>
<li>第三周-超参数调试&amp;正则化&amp;框架-3.2-为超参数选择合适的范围</li>
<li>第三周-超参数调试&amp;正则化&amp;框架-3.3-超参数训练的实践:pandas VS Caviar</li>
<li>第三周-超参数调试&amp;正则化&amp;框架-3.4-正则化网络的激活函数</li>
<li>第三周-超参数调试&amp;正则化&amp;框架-3.5-将Batch Norm拟合进神经网络</li>
<li>第三周-超参数调试&amp;正则化&amp;框架-3.6-Batch Norm为什么凑效</li>
<li>第三周-超参数调试&amp;正则化&amp;框架-3.7-测试时的Batch Norm</li>
<li>第三周-超参数调试&amp;正则化&amp;框架-3.8-Softmax回归</li>
<li>第三周-超参数调试&amp;正则化&amp;框架-3.9-训练一个Softmax分类器</li>
<li>第三周-超参数调试&amp;正则化&amp;框架-3.10-深度学习框架</li>
<li>第三周-超参数调试&amp;正则化&amp;框架-3.11-TensorFlow</li>
</ul>
</li>
<li><p>3_结构化机器学习项目</p>
<ul>
<li>第一周-机器学习策略上-1.1-什么是ML策略</li>
<li>第一周-机器学习策略上-1.2-正交化</li>
<li>第一周-机器学习策略上-1.3-单一数字评估指标</li>
<li>第一周-机器学习策略上-1.4-满足和优化指标</li>
<li>第一周-机器学习策略上-1.5-训练/开发/测试集划分</li>
<li>第一周-机器学习策略上-1.6-开发集和测试集的大小</li>
<li>第一周-机器学习策略上-1.7-什么时候该改变开发集/测试集和指标</li>
<li>第一周-机器学习策略上-1.8-为什么是人的表现</li>
<li>第一周-机器学习策略上-1.9-可避免偏差</li>
<li>第一周-机器学习策略上-1.10-理解人的表现</li>
<li>第一周-机器学习策略上-1.11-超过人的表现</li>
<li>第一周-机器学习策略上-1.12-改善你的模型表现</li>
<li></li>
<li>第二周-机器学习策略下-2.1-进行误差分析</li>
<li>第二周-机器学习策略下-2.2-清楚标记错误的数据</li>
<li>第二周-机器学习策略下-2.3-快速搭建你的第一个系统并迭代</li>
<li>第二周-机器学习策略下-2.4-在不同数据划分上进行训练并测试</li>
<li>第二周-机器学习策略下-2.5-不匹配数据划分的偏差和方差</li>
<li>第二周-机器学习策略下-2.6-定位数据不匹配</li>
<li>第二周-机器学习策略下-2.7-迁移学习</li>
<li>第二周-机器学习策略下-2.8-多任务学习</li>
<li>第二周-机器学习策略下-2.9-什么是端到端的深度学习</li>
<li>第二周-机器学习策略下-2.10-是否要使用端到端的深度学习</li>
</ul>
</li>
<li><p>4_卷积神经网络</p>
<ul>
<li>第一周-卷积神经网络-1.1-计算机视觉</li>
<li>第一周-卷积神经网络-1.2-边缘检测示例</li>
<li>第一周-卷积神经网络-1.3-更多边缘检测内容</li>
<li>第一周-卷积神经网络-1.4-Padding</li>
<li>第一周-卷积神经网络-1.5-卷积步长</li>
<li>第一周-卷积神经网络-1.6-卷积中”卷”的体现之处</li>
<li>第一周-卷积神经网络-1.7-单层卷积网络</li>
<li>第一周-卷积神经网络-1.8-简单卷积网络示例</li>
<li>第一周-卷积神经网络-1.9-池化层</li>
<li>第一周-卷积神经网络-1.10-卷积神经网络示例</li>
<li>第一周-卷积神经网络-1.11-为什么使用卷积？</li>
<li></li>
<li>第二周-深层卷积神经网络实例探究-2.1-为什么要进行实例探究</li>
<li>第二周-深层卷积神经网络实例探究-2.2-经典网络</li>
<li>第二周-深层卷积神经网络实例探究-2.3-残差网络</li>
<li>第二周-深层卷积神经网络实例探究-2.4-残差网络为什么有用?</li>
<li>第二周-深层卷积神经网络实例探究-2.5-网络中的网络以及1X1网络</li>
<li>第二周-深层卷积神经网络实例探究-2.6-谷歌Inception网络简介</li>
<li>第二周-深层卷积神经网络实例探究-2.7-Inception网络</li>
<li>第二周-深层卷积神经网络实例探究-2.8-使用开源的实现方案</li>
<li>第二周-深层卷积神经网络实例探究-2.9-迁移学习</li>
<li>第二周-深层卷积神经网络实例探究-2.10-数据扩充</li>
<li>第二周-深层卷积神经网络实例探究-2.11-计算机视觉现状</li>
<li></li>
<li>第三周-目标检测-3.1-目标定位</li>
<li>第三周-目标检测-3.2-特征点检测</li>
<li>第三周-目标检测-3.3-目标检测</li>
<li>第三周-目标检测-3.4-卷积的滑动窗口实现</li>
<li>第三周-目标检测-3.5-BoundingBox预测</li>
<li>第三周-目标检测-3.6-并交化</li>
<li>第三周-目标检测-3.7-非极大值抑制</li>
<li>第三周-目标检测-3.8-Anchor Boxes</li>
<li>第三周-目标检测-3.9-YOLO算法</li>
<li>第三周-目标检测-3.10-(选修)RPN网络</li>
<li></li>
<li>第四周-人脸识别和神经风格转换-4.1-什么是人脸识别？</li>
<li>第四周-人脸识别和神经风格转换-4.2-One-Shot学习</li>
<li>第四周-人脸识别和神经风格转换-4.3-Siamese网络</li>
<li>第四周-人脸识别和神经风格转换-4.4-Triplet损失</li>
<li>第四周-人脸识别和神经风格转换-4.5-面部特征与二分类</li>
<li>第四周-人脸识别和神经风格转换-4.6-什么是神经风格转换</li>
<li>第四周-人脸识别和神经风格转换-4.7-深度卷积网络在学什么</li>
<li>第四周-人脸识别和神经风格转换-4.8-代价函数</li>
<li>第四周-人脸识别和神经风格转换-4.9-内容代价函数</li>
<li>第四周-人脸识别和神经风格转换-4.10-风格损失函数</li>
<li>第四周-人脸识别和神经风格转换-4.11-一维到三维推广</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/12/04/课程目录/" data-id="cjp962nbx0002f0g63w0orito" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/12/04/assignment2_2_note/">(no title)</a>
          </li>
        
          <li>
            <a href="/2018/12/04/assignment2_1_note/">(no title)</a>
          </li>
        
          <li>
            <a href="/2018/12/04/课程目录/">(no title)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>